<!DOCTYPE html>


<html theme="dark" showBanner="true" hasBanner="false" > 
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
<script src="/blog/js/color.global.min.js" ></script>
<script src="/blog/js/load-settings.js" ></script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-31GM7RWSBJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-31GM7RWSBJ');
</script>

<head>
  <meta charset="utf-8">
  
  
  

  
  <title>骨关节炎X线图像分类 | kusurin.blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <meta name="description" content="前言对一张图片进行分类是CV中的传统任务，在这里我们在Digital Knee X-ray Images上,基于PyTorch使用CNN、Vision Transformer以及Swin Transformer进行这一实验，从X线图像中获取膝关节炎的KL分期。 CNN简单的CNN使用CNN，可以使用卷积逐层提取图像从基础形状到高级形态的特征，例如原始输入-&gt;竖线+横线-&gt;转角-&gt;">
<meta property="og:type" content="article">
<meta property="og:title" content="骨关节炎X线图像分类">
<meta property="og:url" content="https://kusurin.github.io/blog/2025/08/30/OA-classfier/index.html">
<meta property="og:site_name" content="kusurin.blog">
<meta property="og:description" content="前言对一张图片进行分类是CV中的传统任务，在这里我们在Digital Knee X-ray Images上,基于PyTorch使用CNN、Vision Transformer以及Swin Transformer进行这一实验，从X线图像中获取膝关节炎的KL分期。 CNN简单的CNN使用CNN，可以使用卷积逐层提取图像从基础形状到高级形态的特征，例如原始输入-&gt;竖线+横线-&gt;转角-&gt;">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://kusurin.github.io/blog/images/OA-classfier/resnet5_cm.png">
<meta property="og:image" content="https://kusurin.github.io/blog/images/OA-classfier/resnet4_reclass.png">
<meta property="article:published_time" content="2025-08-30T07:36:41.000Z">
<meta property="article:modified_time" content="2025-09-04T15:11:07.387Z">
<meta property="article:author" content="kusurin">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="学习笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kusurin.github.io/blog/images/OA-classfier/resnet5_cm.png">
  
    <link rel="alternate" href="/blog/atom.xml" title="kusurin.blog" type="application/atom+xml">
  
  
    <link rel="icon" media="(prefers-color-scheme: light)" href="/blog/images/favicon-light-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/blog/images/favicon-light-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/blog/images/favicon-light-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: light)" href="/blog/images/favicon-light-192.png" sizes="192x192">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/blog/images/favicon-dark-32.png" sizes="32x32">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/blog/images/favicon-dark-128.png" sizes="128x128">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/blog/images/favicon-dark-180.png" sizes="180x180">
    <link rel="icon" media="(prefers-color-scheme: dark)" href="/blog/images/favicon-dark-192.png" sizes="192x192">
  
  
<link rel="stylesheet" href="/blog/css/style.css">

<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
  
   
  <div id="main-grid" class="shadow   ">
    <div id="nav" class=""  >
      <navbar id="navbar">
  <nav id="title-nav">
    <a href="/blog/">
      <div id="vivia-logo">
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
        <div class="dot"></div>
      </div>
      <div>kusurin.blog </div>
    </a>
  </nav>
  <nav id="main-nav">
    
      <a class="main-nav-link" href="/blog/">Home</a>
    
      <a class="main-nav-link" href="/blog/archives">Archives</a>
    
      <a class="main-nav-link" href="/blog/about">About</a>
    
  </nav>
  <nav id="sub-nav">
    <a id="theme-btn" class="nav-icon">
      <span class="light-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M438.5-829.913v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-829.913Zm0 747.826v-48q0-17.452 11.963-29.476 11.964-12.024 29.326-12.024 17.363 0 29.537 12.024t12.174 29.476v48q0 17.452-11.963 29.476-11.964 12.024-29.326 12.024-17.363 0-29.537-12.024T438.5-82.087ZM877.913-438.5h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537t29.476-12.174h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T877.913-438.5Zm-747.826 0h-48q-17.452 0-29.476-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T82.087-521.5h48q17.452 0 29.476 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T130.087-438.5Zm660.174-290.87-34.239 32q-12.913 12.674-29.565 12.174-16.653-.5-29.327-13.174-12.674-12.673-12.554-28.826.12-16.152 12.794-28.826l33-35q12.913-12.674 30.454-12.674t30.163 12.847q12.709 12.846 12.328 30.826-.38 17.98-13.054 30.653ZM262.63-203.978l-32 34q-12.913 12.674-30.454 12.674t-30.163-12.847q-12.709-12.846-12.328-30.826.38-17.98 13.054-30.653l33.239-31q12.913-12.674 29.565-12.174 16.653.5 29.327 13.174 12.674 12.673 12.554 28.826-.12 16.152-12.794 28.826Zm466.74 33.239-32-33.239q-12.674-12.913-12.174-29.565.5-16.653 13.174-29.327 12.673-12.674 28.826-13.054 16.152-.38 28.826 12.294l35 33q12.674 12.913 12.674 30.454t-12.847 30.163q-12.846 12.709-30.826 12.328-17.98-.38-30.653-13.054ZM203.978-697.37l-34-33q-12.674-12.913-13.174-29.945-.5-17.033 12.174-29.707t31.326-13.293q18.653-.62 31.326 13.054l32 34.239q11.674 12.913 11.174 29.565-.5 16.653-13.174 29.327-12.673 12.674-28.826 12.554-16.152-.12-28.826-12.794ZM480-240q-100 0-170-70t-70-170q0-100 70-170t170-70q100 0 170 70t70 170q0 100-70 170t-170 70Zm-.247-82q65.703 0 111.475-46.272Q637-414.544 637-480.247t-45.525-111.228Q545.95-637 480.247-637t-111.475 45.525Q323-545.95 323-480.247t45.525 111.975Q414.05-322 479.753-322ZM481-481Z"/></svg></span>
      <span class="dark-mode-icon"><svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M480.239-116.413q-152.63 0-258.228-105.478Q116.413-327.37 116.413-480q0-130.935 77.739-227.435t206.304-125.043q43.022-9.631 63.87 10.869t3.478 62.805q-8.891 22.043-14.315 44.463-5.424 22.42-5.424 46.689 0 91.694 64.326 155.879 64.325 64.186 156.218 64.186 24.369 0 46.978-4.946 22.609-4.945 44.413-14.076 42.826-17.369 62.967 1.142 20.142 18.511 10.511 61.054Q807.174-280 712.63-198.206q-94.543 81.793-232.391 81.793Zm0-95q79.783 0 143.337-40.217 63.554-40.218 95.793-108.283-15.608 4.044-31.097 5.326-15.49 1.283-31.859.805-123.706-4.066-210.777-90.539-87.071-86.473-91.614-212.092-.24-16.369.923-31.978 1.164-15.609 5.446-30.978-67.826 32.478-108.282 96.152Q211.652-559.543 211.652-480q0 111.929 78.329 190.258 78.329 78.329 190.258 78.329ZM466.13-465.891Z"/></svg></span>
    </a>
    
      <a id="nav-rss-link" class="nav-icon mobile-hide" href="/blog/atom.xml" title="RSS 订阅">
        <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M198-120q-25.846 0-44.23-18.384-18.384-18.385-18.384-44.23 0-25.846 18.384-44.23 18.384-18.385 44.23-18.385 25.846 0 44.23 18.385 18.384 18.384 18.384 44.23 0 25.845-18.384 44.23Q223.846-120 198-120Zm538.385 0q-18.846 0-32.923-13.769-14.076-13.769-15.922-33.23-8.692-100.616-51.077-188.654-42.385-88.039-109.885-155.539-67.5-67.501-155.539-109.885Q283-663.462 182.385-672.154q-19.461-1.846-33.23-16.23-13.769-14.385-13.769-33.846t14.076-32.922q14.077-13.461 32.923-12.23 120.076 8.692 226.038 58.768 105.961 50.077 185.73 129.846 79.769 79.769 129.846 185.731 50.077 105.961 58.769 226.038 1.231 18.846-12.538 32.922Q756.461-120 736.385-120Zm-252 0q-18.231 0-32.423-13.461t-18.653-33.538Q418.155-264.23 348.886-333.5q-69.27-69.27-166.501-84.423-20.077-4.462-33.538-18.961-13.461-14.5-13.461-33.346 0-19.076 13.884-33.23 13.884-14.153 33.115-10.922 136.769 15.384 234.384 112.999 97.615 97.615 112.999 234.384 3.231 19.23-10.538 33.115Q505.461-120 484.385-120Z"/></svg>
      </a>
    
    <div id="nav-menu-btn" class="nav-icon">
      <svg xmlns="http://www.w3.org/2000/svg" height="20" viewBox="0 -960 960 960" width="20"><path d="M177.37-252.282q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Zm0-186.218q-17.453 0-29.477-11.963-12.024-11.964-12.024-29.326 0-17.363 12.024-29.537T177.37-521.5h605.26q17.453 0 29.477 11.963 12.024 11.964 12.024 29.326 0 17.363-12.024 29.537T782.63-438.5H177.37Zm0-186.217q-17.453 0-29.477-11.964-12.024-11.963-12.024-29.326t12.024-29.537q12.024-12.174 29.477-12.174h605.26q17.453 0 29.477 11.964 12.024 11.963 12.024 29.326t-12.024 29.537q-12.024 12.174-29.477 12.174H177.37Z"/></svg>
    </div>
  </nav>
</navbar>
<div id="nav-dropdown" class="hidden">
  <div id="dropdown-link-list">
    
      <a class="nav-dropdown-link" href="/blog/">Home</a>
    
      <a class="nav-dropdown-link" href="/blog/archives">Archives</a>
    
      <a class="nav-dropdown-link" href="/blog/about">About</a>
    
    
      <a class="nav-dropdown-link" href="/blog/atom.xml" title="RSS 订阅">RSS</a>
     
    </div>
</div>
<script>
  let dropdownBtn = document.getElementById("nav-menu-btn");
  let dropdownEle = document.getElementById("nav-dropdown");
  dropdownBtn.onclick = function() {
    dropdownEle.classList.toggle("hidden");
  }
</script>
    </div>
    <div id="sidebar-wrapper">
      <sidebar id="sidebar">
  
    <div class="widget-wrap">
  <div class="info-card">
    <div class="avatar">
      
        <image src=https://pic1.imgdb.cn/item/6828010758cb8da5c8f7d65d.gif></image>
      
      <div class="img-dim"></div>
    </div>
    <div class="info">
      <div class="username">kusurin </div>
      <div class="dot"></div>
      <div class="subtitle">文字の中に沈む </div>
      <div class="link-list">
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://kusurin.icu" title="Home Page"><i class="fa-solid fa-globe"></i></a>
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://kusurin.icu/blog" title="Blog Home Page"><i class="fa-solid fa-house"></i></a>
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://github.com/kusurin" title="GitHub"><i class="fa-brands fa-github"></i></a>
        
          <a class="link-btn" target="_blank" rel="noopener" href="https://space.bilibili.com/5404263" title="bilibili"><i class="fa-brands fa-bilibili"></i></a>
         
      </div>  
    </div>
  </div>
</div>

  
  <div class="sticky">
    
      


  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">分类</h3>
      <div class="category-box">
            <a class="category-link" href="/blog/categories/Coding/">
                Coding
                <div class="category-count">3</div>
            </a>
        
            <a class="category-link" href="/blog/categories/%E6%9D%82%E8%B0%88/">
                杂谈
                <div class="category-count">13</div>
            </a>
        
            <a class="category-link" href="/blog/categories/CSS-tricks/">
                CSS-tricks
                <div class="category-count">3</div>
            </a>
        
            <a class="category-link" href="/blog/categories/%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/">
                踩坑日记
                <div class="category-count">5</div>
            </a>
        
            <a class="category-link" href="/blog/categories/%E7%94%9F%E4%BF%A1/">
                生信
                <div class="category-count">8</div>
            </a>
        </div>
    </div>
  </div>


    
      
  <div class="widget-wrap">
    <div class="widget">
      <h3 class="widget-title">标签</h3>
      <ul class="widget-tag-list" itemprop="keywords"><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/CSS/" rel="tag">CSS</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/Linux/" rel="tag">Linux</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/Python/" rel="tag">Python</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/R/" rel="tag">R</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/R-based/" rel="tag">R based</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/WPA2/" rel="tag">WPA2</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/scATAC-seq/" rel="tag">scATAC-seq</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/scRNA-seq/" rel="tag">scRNA-seq</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E5%82%85%E7%AB%8B%E5%8F%B6/" rel="tag">傅立叶</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E6%9D%82%E8%B0%88/" rel="tag">杂谈</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E6%A8%A1%E6%8B%9F%E4%BD%8D%E7%BD%AE/" rel="tag">模拟位置</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E7%94%9F%E4%BF%A1/" rel="tag">生信</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E7%A9%BA%E9%97%B4%E8%BD%AC%E5%BD%95%E7%BB%84/" rel="tag">空间转录组</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E7%BB%B4%E4%BF%AE/" rel="tag">维修</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E7%BD%91%E5%AE%89/" rel="tag">网安</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E8%B8%A9%E5%9D%91/" rel="tag">踩坑</a></li><li class="widget-tag-list-item"><a class="widget-tag-list-link" href="/blog/tags/%E8%BE%B9%E6%A1%86/" rel="tag">边框</a></li></ul>
    </div>
  </div>


    
  </div>
</sidebar>
    </div>
    <div id="content-body">
       


<article id="post-OA-classfier" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  
    
   
  <div class="article-inner">
    <div class="article-main">
      <header class="article-header">
        
<div class="main-title-bar">
  <div class="main-title-dot"></div>
  
    
      <h1 class="p-name article-title" itemprop="headline name">
        骨关节炎X线图像分类
      </h1>
    
  
</div>

        <div class='meta-info-bar'>
          <div class="meta-info">
  <time class="dt-published" datetime="2025-08-30T07:36:41.000Z" itemprop="datePublished">2025-08-30</time>
</div>
          <div class="need-seperator meta-info">
            <div class="meta-cate-flex">
  
  <a class="meta-cate-link" href="/blog/categories/Coding/">Coding</a>
   
</div>
  
          </div>
          <div class="wordcount need-seperator meta-info">
            19k 词 
          </div>
        </div>
        
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="tag">学习笔记</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/blog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li></ul>

      </header>
      <div class="e-content article-entry" itemprop="articleBody">
        
          
    <div id="toc">
        <strong class="sidebar-title">目录</strong>
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CNN"><span class="toc-text">CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E7%9A%84CNN"><span class="toc-text">简单的CNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9BCNN"><span class="toc-text">改进CNN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E9%9A%BE%E4%BB%A5%E8%BE%A8%E5%88%AB%E7%9A%84%E6%A0%B7%E6%9C%AC%E7%B1%BB%E8%BF%9B%E8%A1%8C%E9%87%8D%E6%96%B0%E5%88%86%E7%B1%BB"><span class="toc-text">对难以辨别的样本类进行重新分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Swin-Transformer"><span class="toc-text">Swin Transformer</span></a></li></ol>
    </div>

          <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>对一张图片进行分类是CV中的传统任务，在这里我们在<a target="_blank" rel="noopener" href="https://data.mendeley.com/datasets/t9ndx37v5h/1">Digital Knee X-ray Images</a>上,基于PyTorch使用CNN、Vision Transformer以及Swin Transformer进行这一实验，从X线图像中获取膝关节炎的KL分期。</p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><h3 id="简单的CNN"><a href="#简单的CNN" class="headerlink" title="简单的CNN"></a>简单的CNN</h3><p>使用CNN，可以使用卷积逐层提取图像从基础形状到高级形态的特征，例如原始输入-&gt;竖线+横线-&gt;转角-&gt;特定物体，而类似于视觉皮层中对特定方向直线敏感的神经元，如下卷积核即可捕捉竖线特征：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="31.991ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14140 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mtable" transform="translate(278,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mtd" transform="translate(1500,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(3000,0)"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mtext" transform="translate(1278,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mn" transform="translate(1528,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mtd" transform="translate(6028,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(7528,0)"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mtext" fill="red" stroke="red" transform="translate(1278,0)"><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(500,0)"></path></g></g><g data-mml-node="mtd" transform="translate(10806,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(12306,0)"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(13862,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></g></svg></mjx-container></p>
<p>其在如下窗口上取得较大的值：</p>
<p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="33.498ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 14806 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mtable" transform="translate(278,0)"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1000,0)"></path></g></g><g data-mml-node="mtd" transform="translate(2500,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(4000,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mtext" transform="translate(500,0)"><path data-c="A0" d=""></path></g><g data-mml-node="mn" transform="translate(750,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(1000,0)"></path></g></g><g data-mml-node="mtd" transform="translate(7250,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(8750,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mtext" fill="red" stroke="red" transform="translate(500,0)"><path data-c="5C" d="M56 731Q56 740 62 745T75 750Q85 750 92 740Q96 733 270 255T444 -231Q444 -239 438 -244T424 -250Q414 -250 407 -240Q404 -236 230 242T56 731Z"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(500,0)"></path></g><g data-mml-node="mn" transform="translate(1500,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(500,0)"></path></g></g><g data-mml-node="mtd" transform="translate(12250,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mtd" transform="translate(13750,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g><g data-mml-node="mo" transform="translate(14528,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></g></svg></mjx-container></p>
<p>我们先编写一个CNN类的最小实现，输入图像为w256*h256*c1，在torch中定义网络成分如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN, self).__init__()</span><br><span class="line">        <span class="comment">#...</span></span><br></pre></td></tr></table></figure>
<p>卷积层可以这样定义<code>self.conv1=nn.Conv2d(in_channels=1,out_channels=16,kernel_size=3,padding=1)</code>，在输入四周添加空padding可以方便地解决卷积和池化缩小输入后减、除导致大小不为整数。</p>
<p>然后进行标准化，<code>self.bn1 = nn.BatchNorm2d(num_features=16)</code></p>
<p>使用池化层，可以降维减少参数数量，<code>self.pool1=nn.MaxPool2d(kernel_size=2)</code></p>
<p>如此进行3层，通道变为64，输入大小变为256/2/2/2=32，便可以得到图像的高级特征，最后将特征送入线性的全连接层<code>self.classifier=nn.Linear(64*32*32,5)</code></p>
<p>以及我们挑选ReLu作为激活函数<code>elf.relu = nn.ReLU()</code></p>
<p>然后定义网络结构，规定数据流向：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    x=self.conv1(x)</span><br><span class="line">    x=self.bn1(x)</span><br><span class="line">    x=self.relu(x)</span><br><span class="line">    x=self.pool1(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#...</span></span><br><span class="line"></span><br><span class="line">    x=x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">    x=self.classifier(x)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<details>
<summary>完整训练代码</summary>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'device:<span class="subst">{device}</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">seed=<span class="number">42</span></span><br><span class="line">random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)</span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line"></span><br><span class="line">exps={<span class="string">'MedicalExpert-I'</span>,<span class="string">'MedicalExpert-II'</span>}</span><br><span class="line">KL_levels={<span class="string">'0Normal'</span>,<span class="string">'1Doubtful'</span>,<span class="string">'2Mild'</span>,<span class="string">'3Moderate'</span>,<span class="string">'4Severe'</span>}</span><br><span class="line"></span><br><span class="line">img_exp_KLs=[] </span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(<span class="string">f'.<span class="subst">{os.sep}</span>Digital Knee X-ray Images'</span>): </span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> files: </span><br><span class="line">        <span class="keyword">if</span> name.endswith(<span class="string">'.png'</span>):</span><br><span class="line">            path_parts=<span class="built_in">set</span>(root.split(os.sep))</span><br><span class="line">            img_path=os.path.join(root, name)</span><br><span class="line">            img_exp_KL=(img_path,(path_parts&amp;exps).pop(),(path_parts&amp;KL_levels).pop())</span><br><span class="line">            img_exp_KLs.append(img_exp_KL)</span><br><span class="line"></span><br><span class="line">dataset_df = pd.DataFrame(img_exp_KLs,columns=[<span class="string">'img_path'</span>,<span class="string">'exp'</span>,<span class="string">'KL'</span>])</span><br><span class="line"></span><br><span class="line">dataset_df.sort_values(by=<span class="string">'img_path'</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">dataset_df[<span class="string">'filename'</span>] = dataset_df[<span class="string">'img_path'</span>].<span class="built_in">str</span>.split(os.sep).<span class="built_in">str</span>[-<span class="number">1</span>]</span><br><span class="line">dataset_df_unique = dataset_df.drop_duplicates(subset=[<span class="string">'KL'</span>,<span class="string">'filename'</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">256</span>, <span class="number">256</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.5</span>],</span><br><span class="line">                         std=[<span class="number">0.5</span>])</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KneeXRayDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataframe, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.df = dataframe</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        row = self.df.iloc[idx]</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(row[<span class="string">'img_path'</span>]).convert(<span class="string">'L'</span>)</span><br><span class="line">        label = <span class="built_in">int</span>(row[<span class="string">'KL'</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        image = self.transform(image)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image, label</span><br><span class="line"></span><br><span class="line">X = dataset_df_unique</span><br><span class="line">y = dataset_df_unique[<span class="string">'KL'</span>]</span><br><span class="line"></span><br><span class="line">X_train_val, X_test, y_train_val, y_test = train_test_split(</span><br><span class="line">    X, y, test_size=<span class="number">0.2</span>, random_state=seed, stratify=y)</span><br><span class="line"></span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(</span><br><span class="line">    X_train_val, y_train_val, test_size=<span class="number">0.25</span>, random_state=seed, stratify=y_train_val)</span><br><span class="line"></span><br><span class="line">train_dataset = KneeXRayDataset(dataframe=X_train, transform=data_transform)</span><br><span class="line">val_dataset = KneeXRayDataset(dataframe=X_val, transform=data_transform)</span><br><span class="line">test_dataset = KneeXRayDataset(dataframe=X_test, transform=data_transform)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=<span class="number">256</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size=<span class="number">256</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=<span class="number">256</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line">train_dataset_hash=hashlib.md5(<span class="string">''</span>.join(X_train[<span class="string">'filename'</span>].to_list()).encode(<span class="string">'utf-8'</span>)).hexdigest()</span><br><span class="line">val_dataset_hash=hashlib.md5(<span class="string">''</span>.join(X_val[<span class="string">'filename'</span>].to_list()).encode(<span class="string">'utf-8'</span>)).hexdigest()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'train_dataset_hash:<span class="subst">{train_dataset_hash}</span>,val_dataset_hash:<span class="subst">{val_dataset_hash}</span>'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleCNN, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.pool1=nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (256)/2=128</span></span><br><span class="line"></span><br><span class="line">        self.conv2=nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        self.pool2=nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (128)/2=64</span></span><br><span class="line"></span><br><span class="line">        self.conv3=nn.Conv2d(<span class="number">32</span>,<span class="number">64</span>,kernel_size=<span class="number">3</span>,padding=<span class="number">1</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.pool3=nn.MaxPool2d(kernel_size=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># (64)/2=32</span></span><br><span class="line"></span><br><span class="line">        self.classifier=nn.Linear(<span class="number">32</span>*<span class="number">32</span>*<span class="number">64</span>,<span class="number">5</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        x=self.bn1(x)</span><br><span class="line">        x=self.relu(x)</span><br><span class="line">        x=self.pool1(x)</span><br><span class="line"></span><br><span class="line">        x=self.conv2(x)</span><br><span class="line">        x=self.bn2(x)</span><br><span class="line">        x=self.relu(x)</span><br><span class="line">        x=self.pool2(x)</span><br><span class="line"></span><br><span class="line">        x=self.conv3(x)</span><br><span class="line">        x=self.bn3(x)</span><br><span class="line">        x=self.relu(x)</span><br><span class="line">        x=self.pool3(x)</span><br><span class="line"></span><br><span class="line">        x=x.view(x.size(<span class="number">0</span>),-<span class="number">1</span>)</span><br><span class="line">        x=self.classifier(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model=SimpleCNN()</span><br><span class="line"></span><br><span class="line">save_epoch=<span class="number">10</span></span><br><span class="line">latest_model_path=<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span></span><br><span class="line"><span class="keyword">while</span>(<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span>):</span><br><span class="line">    latest_model_path=<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span></span><br><span class="line">    save_epoch+=<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(latest_model_path):</span><br><span class="line">    model.load_state_dict(torch.load(latest_model_path,map_location=device))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Loaded latest model from <span class="subst">{latest_model_path}</span>'</span>)</span><br><span class="line"></span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">num_epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Training for <span class="subst">{num_epochs}</span> epochs'</span>)</span><br><span class="line"></span><br><span class="line">best_val_loss=<span class="built_in">float</span>(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    model.train() <span class="comment"># 切换训练模式</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> tqdm(train_loader, desc=<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>/<span class="subst">{num_epochs}</span>'</span>):</span><br><span class="line">        inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 重置梯度</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward() <span class="comment"># 损失反向传播</span></span><br><span class="line">        optimizer.step() <span class="comment"># 更新权重</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>() <span class="comment"># 切换评估模式</span></span><br><span class="line">    val_loss=<span class="number">0.0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> tqdm(val_loader, desc=<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>/<span class="subst">{num_epochs}</span>'</span>):</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            val_loss += criterion(outputs, labels).item()</span><br><span class="line"></span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Epoch <span class="subst">{epoch+<span class="number">1</span>}</span>/<span class="subst">{num_epochs}</span>, Loss: <span class="subst">{running_loss/<span class="built_in">len</span>(train_loader)}</span>, Val Loss: <span class="subst">{val_loss/<span class="built_in">len</span>(val_loader)}</span>, Val Accuracy: <span class="subst">{<span class="number">100</span>*correct/total}</span>%'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch+<span class="number">1</span>) % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{epoch+<span class="number">1</span>}</span>.pth'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> val_loss/<span class="built_in">len</span>(val_loader) &lt; best_val_loss:</span><br><span class="line">        best_val_loss = val_loss/<span class="built_in">len</span>(val_loader)</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>best_model_<span class="subst">{train_dataset_hash}</span>_on_<span class="subst">{val_dataset_hash}</span>.pth'</span>)</span><br></pre></td></tr></table></figure>

</details>

<p>最终我们的模型在5分类上的表现为72.59%，实在有点不够看。</p>
<h3 id="改进CNN"><a href="#改进CNN" class="headerlink" title="改进CNN"></a>改进CNN</h3><p>接下来我们将骨干网换为ResNet，把分类头改成5分类的线性层，并进行以下改进：</p>
<ul>
<li>对数据集进行反转、旋转、变色等增强。</li>
<li>对损失加上各类负相关的权重。</li>
<li>L2正则化。</li>
<li>动态学习率。</li>
<li>早停。</li>
</ul>
<p>我们自己构建ResNet18试试。<br>（写了才发现原文shortcut在downsample时用的是kernel_size=1, stride=2的卷积核，想着丢失信息可以优化，比如使用池化，结果一查已经有<a target="_blank" rel="noopener" href="https://github.com/leonzfa/iResNet">CVPR</a>干过了ORZ）</p>
<details>
<summary>构建ResNet</summary>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> ResNet18_Weights</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_c,out_c,strides=[<span class="number">1</span>,<span class="number">1</span>],padding=<span class="number">1</span>,downsample=<span class="literal">None</span></span>)-&gt;<span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>(BasicBlock, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1=nn.Conv2d(in_c,out_c,kernel_size=<span class="number">3</span>,stride=strides[<span class="number">0</span>],padding=padding,bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1=nn.BatchNorm2d(out_c)</span><br><span class="line">        self.relu=nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2=nn.Conv2d(out_c,out_c,kernel_size=<span class="number">3</span>,stride=strides[<span class="number">1</span>],padding=padding,bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2=nn.BatchNorm2d(out_c)</span><br><span class="line">        self.downsample=downsample</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out=self.conv1(x)</span><br><span class="line">        out=self.bn1(out)</span><br><span class="line">        out=self.relu(out)</span><br><span class="line">        </span><br><span class="line">        out=self.conv2(out)</span><br><span class="line">        out=self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity=self.downsample(identity)</span><br><span class="line">        out+=identity</span><br><span class="line">        out=self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet18</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,num_classes=<span class="number">1000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet18,self).__init__()</span><br><span class="line"></span><br><span class="line">        self.in_c=<span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1=nn.Conv2d(<span class="number">3</span>,self.in_c,kernel_size=<span class="number">7</span>,stride=<span class="number">2</span>,padding=<span class="number">3</span>,bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1=nn.BatchNorm2d(self.in_c)</span><br><span class="line">        self.relu=nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool=nn.MaxPool2d(kernel_size=<span class="number">3</span>,stride=<span class="number">2</span>,padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.layer1=self._make_layer(<span class="number">64</span>,strides=[<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">        self.layer2=self._make_layer(<span class="number">128</span>,strides=[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">        self.layer3=self._make_layer(<span class="number">256</span>,strides=[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">        self.layer4=self._make_layer(<span class="number">512</span>,strides=[<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        self.avgpool=nn.AdaptiveAvgPool2d(output_size=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc=nn.Linear(<span class="number">512</span>,num_classes,bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layer</span>(<span class="params">self,out_c,strides=[<span class="number">1</span>,<span class="number">1</span>]</span>):</span><br><span class="line">        downsample=<span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> strides[<span class="number">0</span>]!=<span class="number">1</span>:</span><br><span class="line">            downsample=nn.Sequential(</span><br><span class="line">                nn.Conv2d(self.in_c,out_c,kernel_size=<span class="number">1</span>,stride=strides[<span class="number">0</span>],bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_c)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers=[]</span><br><span class="line">        layers.append(</span><br><span class="line">            BasicBlock(</span><br><span class="line">                self.in_c,out_c,strides=[<span class="number">2</span>,<span class="number">1</span>],downsample=downsample,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        self.in_c=out_c</span><br><span class="line">        layers.append(</span><br><span class="line">            BasicBlock(</span><br><span class="line">                self.in_c,out_c,</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x=self.conv1(x)</span><br><span class="line">        x=self.bn1(x)</span><br><span class="line">        x=self.relu(x)</span><br><span class="line">        x=self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x=self.layer1(x)</span><br><span class="line">        x=self.layer2(x)</span><br><span class="line">        x=self.layer3(x)</span><br><span class="line">        x=self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x=self.avgpool(x)</span><br><span class="line">        x=torch.flatten(x,<span class="number">1</span>)</span><br><span class="line">        x=self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model=ResNet18(num_classes=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">model_ref=models.resnet18(weights=ResNet18_Weights.DEFAULT)</span><br><span class="line"></span><br><span class="line">model.load_state_dict(model_ref.state_dict(),strict=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</details>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># &lt;All keys matched successfully&gt;</span></span><br></pre></td></tr></table></figure>
<p>\(^o^)/</p>
<details>
<summary>完整训练代码</summary>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">KneeXRayDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dataframe, transform=<span class="literal">None</span>, cache_size=<span class="number">2000</span></span>):</span><br><span class="line">        self.df = dataframe</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.cache={}</span><br><span class="line">        self.cache_size=cache_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.df)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="keyword">if</span> idx <span class="keyword">in</span> self.cache:</span><br><span class="line">            <span class="keyword">return</span> self.cache[idx]</span><br><span class="line"></span><br><span class="line">        row = self.df.iloc[idx]</span><br><span class="line"></span><br><span class="line">        image = Image.<span class="built_in">open</span>(row[<span class="string">'img_path'</span>]).convert(<span class="string">'RGB'</span>)</span><br><span class="line">        label = <span class="built_in">int</span>(row[<span class="string">'KL'</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        image = self.transform(image)</span><br><span class="line"></span><br><span class="line">        result=(image, label)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.cache) &lt; self.cache_size:</span><br><span class="line">            self.cache[idx] = result</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'device:<span class="subst">{device}</span>'</span>)</span><br><span class="line"></span><br><span class="line">    seed=<span class="number">42</span></span><br><span class="line">    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br><span class="line"></span><br><span class="line">    exps={<span class="string">'MedicalExpert-I'</span>,<span class="string">'MedicalExpert-II'</span>}</span><br><span class="line">    KL_levels={<span class="string">'0Normal'</span>,<span class="string">'1Doubtful'</span>,<span class="string">'2Mild'</span>,<span class="string">'3Moderate'</span>,<span class="string">'4Severe'</span>}</span><br><span class="line"></span><br><span class="line">    img_exp_KLs=[] </span><br><span class="line">    <span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(<span class="string">f'.<span class="subst">{os.sep}</span>Digital Knee X-ray Images'</span>): </span><br><span class="line">        <span class="keyword">for</span> name <span class="keyword">in</span> files: </span><br><span class="line">            <span class="keyword">if</span> name.endswith(<span class="string">'.png'</span>):</span><br><span class="line">                path_parts=<span class="built_in">set</span>(root.split(os.sep))</span><br><span class="line">                img_path=os.path.join(root, name)</span><br><span class="line">                img_exp_KL=(img_path,(path_parts&amp;exps).pop(),(path_parts&amp;KL_levels).pop())</span><br><span class="line">                img_exp_KLs.append(img_exp_KL)</span><br><span class="line"></span><br><span class="line">    dataset_df = pd.DataFrame(img_exp_KLs,columns=[<span class="string">'img_path'</span>,<span class="string">'exp'</span>,<span class="string">'KL'</span>])</span><br><span class="line"></span><br><span class="line">    dataset_df.sort_values(by=<span class="string">'img_path'</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    dataset_df[<span class="string">'filename'</span>] = dataset_df[<span class="string">'img_path'</span>].<span class="built_in">str</span>.split(os.sep).<span class="built_in">str</span>[-<span class="number">1</span>]</span><br><span class="line">    dataset_df_unique = dataset_df.drop_duplicates(subset=[<span class="string">'KL'</span>,<span class="string">'filename'</span>]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    data_transform_train = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.RandomRotation(<span class="number">15</span>),</span><br><span class="line">        transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.2</span>),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                             std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    data_transform_val = transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],</span><br><span class="line">                             std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    X = dataset_df_unique</span><br><span class="line">    y = dataset_df_unique[<span class="string">'KL'</span>]</span><br><span class="line"></span><br><span class="line">    X_train_val, X_test, y_train_val, y_test = train_test_split(</span><br><span class="line">        X, y, test_size=<span class="number">0.2</span>, random_state=seed, stratify=y)</span><br><span class="line"></span><br><span class="line">    X_train, X_val, y_train, y_val = train_test_split(</span><br><span class="line">        X_train_val, y_train_val, test_size=<span class="number">0.25</span>, random_state=seed, stratify=y_train_val)</span><br><span class="line">    </span><br><span class="line">    class_counts=Counter(y_train)</span><br><span class="line">    all_counts=<span class="built_in">len</span>(y_train)</span><br><span class="line">    class_weights={cls:all_counts/cnt <span class="keyword">for</span> cls,cnt <span class="keyword">in</span> class_counts.items()}</span><br><span class="line">    class_weights=torch.tensor(<span class="built_in">list</span>(class_weights.values()),dtype=torch.float32).to(device)</span><br><span class="line"></span><br><span class="line">    train_dataset = KneeXRayDataset(dataframe=X_train, transform=data_transform_train)</span><br><span class="line">    val_dataset = KneeXRayDataset(dataframe=X_val, transform=data_transform_val)</span><br><span class="line">    test_dataset = KneeXRayDataset(dataframe=X_test, transform=data_transform_val)</span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(train_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>, </span><br><span class="line">                            num_workers=<span class="number">4</span>,pin_memory=<span class="literal">True</span>,persistent_workers=<span class="literal">True</span>)</span><br><span class="line">    val_loader = DataLoader(val_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>, </span><br><span class="line">                            num_workers=<span class="number">4</span>,pin_memory=<span class="literal">True</span>,persistent_workers=<span class="literal">True</span>)</span><br><span class="line">    test_loader = DataLoader(test_dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    train_dataset_hash=hashlib.md5(<span class="string">''</span>.join(X_train[<span class="string">'filename'</span>].to_list()).encode(<span class="string">'utf-8'</span>)).hexdigest()</span><br><span class="line">    val_dataset_hash=hashlib.md5(<span class="string">''</span>.join(X_val[<span class="string">'filename'</span>].to_list()).encode(<span class="string">'utf-8'</span>)).hexdigest()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'train_dataset_hash:<span class="subst">{train_dataset_hash}</span>,val_dataset_hash:<span class="subst">{val_dataset_hash}</span>'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    model=models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line">    num_ftrs = model.fc.in_features</span><br><span class="line">    model.fc = nn.Linear(num_ftrs, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    save_epoch=<span class="number">100</span></span><br><span class="line">    latest_model_path=<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span></span><br><span class="line">    <span class="keyword">while</span>(os.path.exists(<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span>)):</span><br><span class="line">        latest_model_path=<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{save_epoch}</span>.pth'</span></span><br><span class="line">        save_epoch+=<span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(latest_model_path):</span><br><span class="line">        model.load_state_dict(torch.load(latest_model_path,map_location=device))</span><br><span class="line">        save_epoch-=<span class="number">100</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'Loaded latest model from <span class="subst">{latest_model_path}</span>'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        save_epoch=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    criterion = nn.CrossEntropyLoss(weight=class_weights)</span><br><span class="line"></span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=<span class="number">1e-5</span>, weight_decay=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, <span class="string">'min'</span>, patience=<span class="number">10</span>, factor=<span class="number">0.5</span>, min_lr=<span class="number">1e-7</span>)</span><br><span class="line"></span><br><span class="line">    num_epochs = <span class="number">2000</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f'Training for <span class="subst">{num_epochs}</span> epochs'</span>)</span><br><span class="line"></span><br><span class="line">    best_val_loss=<span class="built_in">float</span>(<span class="string">'inf'</span>)</span><br><span class="line"></span><br><span class="line">    early_stopping_patience = <span class="number">50</span></span><br><span class="line">    patience_counter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(save_epoch,num_epochs+save_epoch+<span class="number">1</span>):</span><br><span class="line">        model.train()</span><br><span class="line">        running_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> tqdm(train_loader, desc=<span class="string">f'Epoch <span class="subst">{epoch}</span>/<span class="subst">{num_epochs}</span>'</span>):</span><br><span class="line">            inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        val_loss=<span class="number">0.0</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> tqdm(val_loader, desc=<span class="string">f'Epoch <span class="subst">{epoch}</span>/<span class="subst">{num_epochs}</span>'</span>):</span><br><span class="line">                inputs, labels = inputs.to(device), labels.to(device)</span><br><span class="line">                outputs = model(inputs)</span><br><span class="line">                val_loss += criterion(outputs, labels).item()</span><br><span class="line"></span><br><span class="line">                _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">                total += labels.size(<span class="number">0</span>)</span><br><span class="line">                correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        epoch_val_loss = val_loss/<span class="built_in">len</span>(val_loader)</span><br><span class="line"></span><br><span class="line">        scheduler.step(epoch_val_loss)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f"Epoch <span class="subst">{epoch}</span>/<span class="subst">{num_epochs}</span>, Loss: <span class="subst">{running_loss/<span class="built_in">len</span>(train_loader)}</span>, Val Loss: <span class="subst">{epoch_val_loss}</span>, Val Accuracy: <span class="subst">{<span class="number">100</span>*correct/total}</span>%, lr: <span class="subst">{optimizer.param_groups[<span class="number">0</span>][<span class="string">'lr'</span>]}</span>"</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>best_model_<span class="subst">{train_dataset_hash}</span>_on_<span class="subst">{val_dataset_hash}</span>.log'</span>,<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">f"epoch:<span class="subst">{epoch}</span>,train_loss:<span class="subst">{running_loss/<span class="built_in">len</span>(train_loader)}</span>,val_loss:<span class="subst">{epoch_val_loss}</span>,val_acc:<span class="subst">{<span class="number">100</span>*correct/total}</span>%,lr:<span class="subst">{optimizer.param_groups[<span class="number">0</span>][<span class="string">'lr'</span>]}</span>\n"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (epoch) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>model_<span class="subst">{train_dataset_hash}</span>_epoch<span class="subst">{epoch}</span>.pth'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch_val_loss &lt; best_val_loss:</span><br><span class="line">            best_val_loss = epoch_val_loss</span><br><span class="line">            torch.save(model.state_dict(), <span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>best_model_<span class="subst">{train_dataset_hash}</span>_on_<span class="subst">{val_dataset_hash}</span>.pth'</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>best_model_<span class="subst">{train_dataset_hash}</span>_on_<span class="subst">{val_dataset_hash}</span>.log'</span>,<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(<span class="string">f'epoch:<span class="subst">{epoch}</span>,saved best model\n'</span>)</span><br><span class="line">            </span><br><span class="line">            patience_counter=<span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            patience_counter+=<span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> patience_counter &gt;= early_stopping_patience:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f'Early stopping triggered at epoch <span class="subst">{epoch}</span>'</span>)</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f'.<span class="subst">{os.sep}</span>models<span class="subst">{os.sep}</span>best_model_<span class="subst">{train_dataset_hash}</span>_on_<span class="subst">{val_dataset_hash}</span>.log'</span>,<span class="string">'a'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(<span class="string">f'epoch:<span class="subst">{epoch}</span>,early stopping\n'</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

</details>

<p>最后我们的准确率为78.01%，涨了差不多6个点。</p>
<h3 id="对难以辨别的样本类进行重新分类"><a href="#对难以辨别的样本类进行重新分类" class="headerlink" title="对难以辨别的样本类进行重新分类"></a>对难以辨别的样本类进行重新分类</h3><p>从混淆矩阵中可以发现，模型对1Doubtful的分类效果尤差。我们推测，1Doubtful含有符合其他类别的多种特征，人类也难以辨别。</p>
<img src="/blog/images/OA-classfier/resnet5_cm.png" style="max-height:40vh;width:auto;">

<p>接下来我们先从训练集中去掉这一类，然后用训练好的模型对这些样本进行重新分类。</p>
<p>新的4分类模型的准确率达到了87.65%，堪堪能看。</p>
<p>而对1Doubtful进行重新分类，使用softmax输出置信度，我们发现有很多样本十分符合其他类的特征，还有一些样本难以分辨，这其中的临床机制可能还需要进一步研究，KL分期或许还有改进的空间。</p>
<img src="/blog/images/OA-classfier/resnet4_reclass.png" style="max-height:40vh;width:auto;">

<h2 id="Swin-Transformer"><a href="#Swin-Transformer" class="headerlink" title="Swin Transformer"></a>Swin Transformer</h2><p>关于Swin Transformer的知识，可以去<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/367111046">这里</a>学习。</p>
<p>我们只要加载预训练模型并更换分类头就好了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.models.swin_transformer <span class="keyword">import</span> swin_b, Swin_B_Weights</span><br><span class="line"></span><br><span class="line">model = swin_b(weights=Swin_B_Weights.DEFAULT)</span><br><span class="line">model.head=nn.Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">4</span>, bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>最终Swin Transformer在5分类上取得了80%的正确率，仍然是对1Doubtful的分类效果尤差。</p>
<p>而在4分类任务上取得了88%的正确率。</p>
<p>提升不是很大就不细讲了。</p>

        
      </div>

         
    </div>
    
     
  </div>
  
    
<nav id="article-nav">
  <a class="article-nav-btn left "
    
      href="/blog/2030/01/16/saki-idou/"
      title="祥，移動"
     >
    <i class="fa-solid fa-angle-left"></i>
    <p class="title-text">
      
        祥，移動
        
    </p>
  </a>
  <a class="article-nav-btn right "
    
      href="/blog/2025/07/25/its-a-trap-2025/"
      title="踩坑日记[2025]"
     >

    <p class="title-text">
      
        踩坑日记[2025]
        
    </p>
    <i class="fa-solid fa-angle-right"></i>
  </a>
</nav>


  
</article>




    </div>
    <div id="footer-wrapper">
      <footer id="footer">
  
  <div id="footer-info" class="inner">
    
    &copy; 2025 kusurin<br>
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & Theme <a target="_blank" rel="noopener" href="https://github.com/saicaca/hexo-theme-vivia">Vivia</a>
  </div>
</footer>

    </div>
    <div class="back-to-top-wrapper">
    <button id="back-to-top-btn" class="back-to-top-btn hide" onclick="topFunction()">
        <i class="fa-solid fa-angle-up"></i>
    </button>
</div>

<script>
    function topFunction() {
        window.scroll({ top: 0, behavior: 'smooth' });
    }
    let btn = document.getElementById('back-to-top-btn');
    function scrollFunction() {
        if (document.body.scrollTop > 600 || document.documentElement.scrollTop > 600) {
            btn.classList.remove('hide')
        } else {
            btn.classList.add('hide')
        }
    }
    window.onscroll = function() {
        scrollFunction();
    }
</script>

  </div>
  <script src="/blog/js/light-dark-switch.js"></script>
</body>
</html>
